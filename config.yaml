data:  # data related config
  label_col: "price"   # column name of the predictor variable
  categorical_cols: ["mainroad", "guestroom", "basement", "hotwaterheating",  # categorical column names in the input data
                   "airconditioning", "prefarea", "furnishingstatus"]
  numeric_cols: ["area", "bedrooms", "bathrooms", "stories", "parking"]   # numerical column names in the input data
  preprocessor_path: "./artefacts/preprocessor.joblib"   # save path of the preprocessing transformations (parameters are learned from the train data)

model:   # model related parameters and hyperparameters
  model_name: "house_price-regression"   # The name with which the model should be saved or logged
  save_path: "./artefacts/"   # model save path
  train_batch_size: 64    # model training batch size (number of data point in single training step/pass through the model)
  test_batch_size: 64   # model test/val batch size (number of data points in a single pass through the model)
  n_epochs: 1000    # number of epochs - how many times the model should pass through the entire training split of the data
  learning_rate: 0.01   # learning rate of the model optimiser
  es_patience: 10   # early stopping patience - how many more training epochs will be attempted if there is no improvement in model observed
  es_delta: 0   # early stopping delta - what increment in model performance will be considered as improvement for early stopping
  use_gpu: True   # to use gpu or not. If no gpu found, will fall back to cpu with warning

mlflow:  # for mlflow logging
  tracking_uri: "http://localhost:5000"   # MLFlow tracking uri. Use http://host.docker.internal:5000 if the MLFlow is running in a docker container
  expt_name: "expt-name"   # Experiment name under which the model trainings will be listed in MLFlow
  deploy_as_code: False   # Enable or disable deploy as code (automatic model registration and add alias for the new model that is ready to deploy)
  model_register_name: "house_price_prediction_prod"    # Name with which model will be registered in MLFLow for deploy-as-code
  model_alias: "champion"   # The alias for the registered model that is ready for deployment

dvc:
  git_repo_url: "https://github.com/digicatapult/bridgeAI-regression-model-data-ingestion.git"  # The repo where the data is present
  git_branch: "feature/testing"   # The branch where the tagged data is available
  data_version: "data-v1.0.0"   # The git tag for the data version to be used
  train_data_path: "./artefacts/train_data.csv"  # Path of the train split of the data pulled from dvc
  test_data_path: "./artefacts/test_data.csv"   # Path of the test split of the data pulled from dvc
  val_data_path: "./artefacts/val_data.csv"   # Path of the validation split of the data pulled from dvc
  dvc_remote: "s3://artifacts"   # remote s3 bucket path for dvc to push and store data
  dvc_remote_name: "regression-model-remote"    # a name assigned to the remote
  dvc_endpoint_url: "http://minio"  # dvc endpoint url
  dvc_region: "us-east-1"    # dvc region - used for s3, just a placeholder for minio
